{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44f9d0d1-1ab6-4e91-8060-fbdacbb17c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Kansas Saloon Smashers \n",
      "Genre: unknown \n",
      "Description: \n",
      "A bartender is working at a saloon, serving drinks to customers. After he fills a stereotypically Irish man's bucket with beer, Carrie Nation and her followers burst inside. They assault the Irish man, pulling his hat over his eyes and then dumping the beer over his head. The group then begin wrecking the bar, smashing the fixtures, mirrors, and breaking the cash register. The bartender then sprays seltzer water in Nation's face before a group of policemen appear and order everybody to leave.[1]\n",
      "\n",
      "Title: Love by the Light of the Moon \n",
      "Genre: unknown \n",
      "Description: \n",
      "The moon, painted with a smiling face hangs over a park at night. A young couple walking past a fence learn on a railing and look up. The moon smiles. They embrace, and the moon's smile gets bigger. They then sit down on a bench by a tree. The moon's view is blocked, causing him to frown. In the last scene, the man fans the woman with his hat because the moon has lef\n"
     ]
    }
   ],
   "source": [
    "# Movie Summary Generator from transformer architecture. Using Wikipedia movie summaries from Kaggle.\n",
    "\n",
    "# Following guidelines from ShakespeareGPT by Andrej Karpathy\n",
    "\n",
    "# First read in the entire dataset\n",
    "import re\n",
    "\n",
    "\n",
    "with open('summaries.txt', 'r', encoding='utf8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "#ensure that there are only Latin and special character wording. CJK characters are removed.\n",
    "pattern = re.compile(r'[^\\x00-\\x7F0-9\\[\\]]+')\n",
    "text = pattern.sub('', text)\n",
    "\n",
    "#first 1000 characters in the text\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0163f53b-5b8d-4817-844e-3c0350947c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]_`abcdefghijklmnopqrstuvwxyz{|}~\n",
      "95\n"
     ]
    }
   ],
   "source": [
    "# find all unique characters in the text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1002d6d-f38b-491f-8d5f-353f6636f0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41, 69, 76, 76, 79, 1, 56, 79, 82, 76, 68, 2]\n",
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "# encode characters\n",
    "\n",
    "enc_map = {}\n",
    "dec_map = {}\n",
    "\n",
    "for i, character in enumerate(chars):\n",
    "    enc_map[character] = i\n",
    "    dec_map[i] = character\n",
    "\n",
    "def encode(s : str) -> list:\n",
    "    ls = []\n",
    "    for char in s:\n",
    "        ls.append(enc_map[char])\n",
    "    return ls\n",
    "\n",
    "def decode(ls : list) -> str:\n",
    "    char_list = []\n",
    "    for i in ls: \n",
    "        char_list.append(dec_map[i]) \n",
    "    s = ''.join(char_list)\n",
    "    return s\n",
    "\n",
    "# general tokenization over instead of using OpenAI's tiktoken tokenization.\n",
    "\n",
    "print(encode('Hello World!'))\n",
    "print(decode(encode('Hello World!')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fde7cc07-8ea7-4205-9eba-ff72508b80cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([77429335]) <built-in method type of Tensor object at 0x0000024982B9AE30>\n",
      "tensor([53, 73, 84, 76, 69, 27,  1, 44, 65, 78, 83, 65, 83,  1, 52, 65, 76, 79,\n",
      "        79, 78,  1, 52, 77, 65, 83, 72, 69, 82, 83,  1,  0, 40, 69, 78, 82, 69,\n",
      "        27,  1, 85, 78, 75, 78, 79, 87, 78,  1,  0, 37, 69, 83, 67, 82, 73, 80,\n",
      "        84, 73, 79, 78, 27,  1,  0, 34,  1, 66, 65, 82, 84, 69, 78, 68, 69, 82,\n",
      "         1, 73, 83,  1, 87, 79, 82, 75, 73, 78, 71,  1, 65, 84,  1, 65,  1, 83,\n",
      "        65, 76, 79, 79, 78, 13,  1, 83, 69, 82, 86, 73, 78, 71,  1, 68, 82, 73,\n",
      "        78, 75, 83,  1, 84, 79,  1, 67, 85, 83, 84, 79, 77, 69, 82, 83, 15,  1,\n",
      "        34, 70, 84, 69, 82,  1, 72, 69,  1, 70, 73, 76, 76, 83,  1, 65,  1, 83,\n",
      "        84, 69, 82, 69, 79, 84, 89, 80, 73, 67, 65, 76, 76, 89,  1, 42, 82, 73,\n",
      "        83, 72,  1, 77, 65, 78,  8, 83,  1, 66, 85, 67, 75, 69, 84,  1, 87, 73,\n",
      "        84, 72,  1, 66, 69, 69, 82, 13,  1, 36, 65, 82, 82, 73, 69,  1, 47, 65,\n",
      "        84, 73, 79, 78,  1, 65, 78, 68,  1, 72, 69, 82,  1, 70, 79, 76, 76, 79,\n",
      "        87, 69, 82, 83,  1, 66, 85, 82, 83, 84,  1, 73, 78, 83, 73, 68, 69, 15,\n",
      "         1, 53, 72, 69, 89,  1, 65, 83, 83, 65, 85, 76, 84,  1, 84, 72, 69,  1,\n",
      "        42, 82, 73, 83, 72,  1, 77, 65, 78, 13,  1, 80, 85, 76, 76, 73, 78, 71,\n",
      "         1, 72, 73, 83,  1, 72, 65, 84,  1, 79, 86, 69, 82,  1, 72, 73, 83,  1,\n",
      "        69, 89, 69, 83,  1, 65, 78, 68,  1, 84, 72, 69, 78,  1, 68, 85, 77, 80,\n",
      "        73, 78, 71,  1, 84, 72, 69,  1, 66, 69, 69, 82,  1, 79, 86, 69, 82,  1,\n",
      "        72, 73, 83,  1, 72, 69, 65, 68, 15,  1, 53, 72, 69,  1, 71, 82, 79, 85,\n",
      "        80,  1, 84, 72, 69, 78,  1, 66, 69, 71, 73, 78,  1, 87, 82, 69, 67, 75,\n",
      "        73, 78, 71,  1, 84, 72, 69,  1, 66, 65, 82, 13,  1, 83, 77, 65, 83, 72,\n",
      "        73, 78, 71,  1, 84, 72, 69,  1, 70, 73, 88, 84, 85, 82, 69, 83, 13,  1,\n",
      "        77, 73, 82, 82, 79, 82, 83, 13,  1, 65, 78, 68,  1, 66, 82, 69, 65, 75,\n",
      "        73, 78, 71,  1, 84, 72, 69,  1, 67, 65, 83, 72,  1, 82, 69, 71, 73, 83,\n",
      "        84, 69, 82, 15,  1, 53, 72, 69,  1, 66, 65, 82, 84, 69, 78, 68, 69, 82,\n",
      "         1, 84, 72, 69, 78,  1, 83, 80, 82, 65, 89, 83,  1, 83, 69, 76, 84, 90,\n",
      "        69, 82,  1, 87, 65, 84, 69, 82,  1, 73, 78,  1, 47, 65, 84, 73, 79, 78,\n",
      "         8, 83,  1, 70, 65, 67, 69,  1, 66, 69, 70, 79, 82, 69,  1, 65,  1, 71,\n",
      "        82, 79, 85, 80,  1, 79, 70,  1, 80, 79, 76, 73, 67, 69, 77, 69, 78,  1,\n",
      "        65, 80, 80, 69, 65, 82,  1, 65, 78, 68,  1, 79, 82, 68, 69, 82,  1, 69,\n",
      "        86, 69, 82, 89, 66, 79, 68, 89,  1, 84, 79,  1, 76, 69, 65, 86, 69, 15,\n",
      "        60, 18, 62,  0,  0, 53, 73, 84, 76, 69, 27,  1, 45, 79, 86, 69,  1, 66,\n",
      "        89,  1, 84, 72, 69,  1, 45, 73, 71, 72, 84,  1, 79, 70,  1, 84, 72, 69,\n",
      "         1, 46, 79, 79, 78,  1,  0, 40, 69, 78, 82, 69, 27,  1, 85, 78, 75, 78,\n",
      "        79, 87, 78,  1,  0, 37, 69, 83, 67, 82, 73, 80, 84, 73, 79, 78, 27,  1,\n",
      "         0, 53, 72, 69,  1, 77, 79, 79, 78, 13,  1, 80, 65, 73, 78, 84, 69, 68,\n",
      "         1, 87, 73, 84, 72,  1, 65,  1, 83, 77, 73, 76, 73, 78, 71,  1, 70, 65,\n",
      "        67, 69,  1, 72, 65, 78, 71, 83,  1, 79, 86, 69, 82,  1, 65,  1, 80, 65,\n",
      "        82, 75,  1, 65, 84,  1, 78, 73, 71, 72, 84, 15,  1, 34,  1, 89, 79, 85,\n",
      "        78, 71,  1, 67, 79, 85, 80, 76, 69,  1, 87, 65, 76, 75, 73, 78, 71,  1,\n",
      "        80, 65, 83, 84,  1, 65,  1, 70, 69, 78, 67, 69,  1, 76, 69, 65, 82, 78,\n",
      "         1, 79, 78,  1, 65,  1, 82, 65, 73, 76, 73, 78, 71,  1, 65, 78, 68,  1,\n",
      "        76, 79, 79, 75,  1, 85, 80, 15,  1, 53, 72, 69,  1, 77, 79, 79, 78,  1,\n",
      "        83, 77, 73, 76, 69, 83, 15,  1, 53, 72, 69, 89,  1, 69, 77, 66, 82, 65,\n",
      "        67, 69, 13,  1, 65, 78, 68,  1, 84, 72, 69,  1, 77, 79, 79, 78,  8, 83,\n",
      "         1, 83, 77, 73, 76, 69,  1, 71, 69, 84, 83,  1, 66, 73, 71, 71, 69, 82,\n",
      "        15,  1, 53, 72, 69, 89,  1, 84, 72, 69, 78,  1, 83, 73, 84,  1, 68, 79,\n",
      "        87, 78,  1, 79, 78,  1, 65,  1, 66, 69, 78, 67, 72,  1, 66, 89,  1, 65,\n",
      "         1, 84, 82, 69, 69, 15,  1, 53, 72, 69,  1, 77, 79, 79, 78,  8, 83,  1,\n",
      "        86, 73, 69, 87,  1, 73, 83,  1, 66, 76, 79, 67, 75, 69, 68, 13,  1, 67,\n",
      "        65, 85, 83, 73, 78, 71,  1, 72, 73, 77,  1, 84, 79,  1, 70, 82, 79, 87,\n",
      "        78, 15,  1, 42, 78,  1, 84, 72, 69,  1, 76, 65, 83, 84,  1, 83, 67, 69,\n",
      "        78, 69, 13,  1, 84, 72, 69,  1, 77, 65, 78,  1, 70, 65, 78, 83,  1, 84,\n",
      "        72, 69,  1, 87, 79, 77, 65, 78,  1, 87, 73, 84, 72,  1, 72, 73, 83,  1,\n",
      "        72, 65, 84,  1, 66, 69, 67, 65, 85, 83, 69,  1, 84, 72, 69,  1, 77, 79,\n",
      "        79, 78,  1, 72, 65, 83,  1, 76, 69, 70])\n"
     ]
    }
   ],
   "source": [
    "# Now using PyTorch store it into a PyTorch Tensor. \n",
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.type)\n",
    "\n",
    "#print first 1000 tokens from tensor\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25b73f31-05a4-4289-9419-cb8d148bfdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting into training and tests/validation sets\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "test_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd103321-c48a-4ac2-bdde-1400463153dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([53, 73, 84, 76, 69, 27,  1, 44, 65])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Maximum length of block size, or maximum length for predictions\n",
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0a79a09-226d-4e88-98e1-45cd3b3bb0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs\n",
      "torch.Size([4, 8])\n",
      "tensor([[68, 89, 83, 67, 65, 76, 67, 85],\n",
      "        [65, 78, 68,  1, 76, 69, 65, 86],\n",
      "        [69, 65, 86, 69, 83,  1, 84, 72],\n",
      "        [69,  1, 35, 82, 73, 84, 73, 83]])\n",
      "targets\n",
      "torch.Size([4, 8])\n",
      "tensor([[89, 83, 67, 65, 76, 67, 85, 76],\n",
      "        [78, 68,  1, 76, 69, 65, 86, 69],\n",
      "        [65, 86, 69, 83,  1, 84, 72, 69],\n",
      "        [ 1, 35, 82, 73, 84, 73, 83, 72]])\n",
      "input: [68], target: 89\n",
      "input: [68, 89], target: 83\n",
      "input: [68, 89, 83], target: 67\n",
      "input: [68, 89, 83, 67], target: 65\n",
      "input: [68, 89, 83, 67, 65], target: 76\n",
      "input: [68, 89, 83, 67, 65, 76], target: 67\n",
      "input: [68, 89, 83, 67, 65, 76, 67], target: 85\n",
      "input: [68, 89, 83, 67, 65, 76, 67, 85], target: 76\n",
      "input: [65], target: 78\n",
      "input: [65, 78], target: 68\n",
      "input: [65, 78, 68], target: 1\n",
      "input: [65, 78, 68, 1], target: 76\n",
      "input: [65, 78, 68, 1, 76], target: 69\n",
      "input: [65, 78, 68, 1, 76, 69], target: 65\n",
      "input: [65, 78, 68, 1, 76, 69, 65], target: 86\n",
      "input: [65, 78, 68, 1, 76, 69, 65, 86], target: 69\n",
      "input: [69], target: 65\n",
      "input: [69, 65], target: 86\n",
      "input: [69, 65, 86], target: 69\n",
      "input: [69, 65, 86, 69], target: 83\n",
      "input: [69, 65, 86, 69, 83], target: 1\n",
      "input: [69, 65, 86, 69, 83, 1], target: 84\n",
      "input: [69, 65, 86, 69, 83, 1, 84], target: 72\n",
      "input: [69, 65, 86, 69, 83, 1, 84, 72], target: 69\n",
      "input: [69], target: 1\n",
      "input: [69, 1], target: 35\n",
      "input: [69, 1, 35], target: 82\n",
      "input: [69, 1, 35, 82], target: 73\n",
      "input: [69, 1, 35, 82, 73], target: 84\n",
      "input: [69, 1, 35, 82, 73, 84], target: 73\n",
      "input: [69, 1, 35, 82, 73, 84, 73], target: 83\n",
      "input: [69, 1, 35, 82, 73, 84, 73, 83], target: 72\n"
     ]
    }
   ],
   "source": [
    "# Now segment into batchs for Stochastic descent & GPU parallelisation\n",
    "\n",
    "# batch size is how many independent sequences in parallel\n",
    "batch_size = 4\n",
    "\n",
    "# generates a small batch of data of inputs x and targets y\n",
    "def get_batch(split : str):\n",
    "    if split == 'train':\n",
    "        data = train_data\n",
    "    else: \n",
    "        data = test_data\n",
    "    # Gets random position to grab a block of data, batch size number of random offsets\n",
    "    # ix is 4 randomly generated numbers between 0 and len(data) - blocksize\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    \n",
    "    # stack all 1D tensors into batch size by block size tensor\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    # y is 1 ahead of x since y trains of all previous context x\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "# this is what gets fed into transformer\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size): #iterate through the tensor\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "        print(f'input: {context.tolist()}, target: {target.tolist()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "419560e8-5a6c-4809-8e11-69fe1320ab9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
     ]
    }
   ],
   "source": [
    "# Now we must feed data through self attention. For now for context of previous terms, we will sum them and average it\n",
    "# The index will take the mean and make a prediction. The nth element will have to take the mean of n-1 terms.\n",
    "\n",
    "# Pre-cursor to self-attention mechanism that makes transformers special.\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "B, T, C = 4, 8, 2 # batch, time, channels\n",
    "# Each batch has a time component (the index for info) and channels which contain the info.\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T)) \n",
    "# triangle matrix (T, T)\n",
    "\n",
    "wei = torch.zeros((T, T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "\n",
    "#softmax is normalization function which defines summing and meaning.\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "print(wei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "292f5300-5fdd-4a61-8aac-475cb26090bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self Attention!\n",
    "\n",
    "B, T, C = 4, 8, 32\n",
    "x = torch.randn(B, T, C)\n",
    "\n",
    "# Instead of summing the values in the tensor, now will have a query and a key.\n",
    "# Query is what I am looking for, Key is what I contain in terms of weight.\n",
    "# Ex: if I am vowel, my key will be align well with query of constanants will have a high affinity.\n",
    "# Affinity between tokens in tensor, dot of key and query = wei.\n",
    "\n",
    "# Single Head of self-attention (normally chat-gpt will have mutliple heads for increased accuracy for attention)\n",
    "head_size = 16\n",
    "# linear transformation template of y = x(A (transpose) ) + b\n",
    "key = nn.Linear(C, head_size, bias=False) # size = (B, T, 16).\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "\n",
    "# independently generated keys and query so they do not have any affinity yet. \n",
    "\n",
    "k = key(x)\n",
    "q = query(x)\n",
    "v = value(x)\n",
    "\n",
    "#here is the dot product to see which of the values generate affinity\n",
    "\n",
    "wei = q @ k.transpose(-2, -1) # due to batch dimension. (B, T, 16) @ (B, 16, T) => (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T)) \n",
    "# triangle matrix (T, T)\n",
    "\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "\n",
    "#softmax is normalization function which defines summing and meaning.\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "# v are the elements we aggregate, not raw x. X is sort of private to this token.\n",
    "out = wei @ v"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
